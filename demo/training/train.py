"""
YOLOv8 ê³„ë€ í’ˆì§ˆ ë¶„ë¥˜ ëª¨ë¸ ê³ ë„í™” í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸
ì „ì²˜ë¦¬ + ë°ì´í„° ë¶„ì„ + í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™” í†µí•©
"""

from ultralytics import YOLO
from pathlib import Path
import argparse
import yaml
from collections import Counter
import cv2
import numpy as np
from tqdm import tqdm
import matplotlib.pyplot as plt


# ============================================================================
# 1. ë°ì´í„° ì „ì²˜ë¦¬ ë° ë¶„ì„
# ============================================================================


def analyze_dataset(data_yaml: str):
    """
    ë°ì´í„°ì…‹ ë¶„ì„: í´ë˜ìŠ¤ ë¶„í¬, ì´ë¯¸ì§€ í’ˆì§ˆ ë“±

    Returns:
        dict: ë¶„ì„ ê²°ê³¼ (class_distribution, image_stats ë“±)
    """
    print("\n" + "=" * 60)
    print("ğŸ“Š ë°ì´í„°ì…‹ ë¶„ì„ ì¤‘...")
    print("=" * 60)

    with open(data_yaml, "r", encoding="utf-8") as f:
        data = yaml.safe_load(f)

    data_path = Path(data["path"])
    train_labels = data_path / data["train"].replace("images", "labels")
    val_labels = data_path / data["val"].replace("images", "labels")

    # í´ë˜ìŠ¤ ë¶„í¬ ë¶„ì„
    train_classes = []
    val_classes = []

    print("\n[1/3] ë¼ë²¨ íŒŒì¼ ì½ëŠ” ì¤‘...")
    for label_file in tqdm(list(train_labels.glob("*.txt"))):
        with open(label_file, "r") as f:
            for line in f:
                class_id = int(line.split()[0])
                train_classes.append(class_id)

    for label_file in tqdm(list(val_labels.glob("*.txt"))):
        with open(label_file, "r") as f:
            for line in f:
                class_id = int(line.split()[0])
                val_classes.append(class_id)

    # í†µê³„ ì¶œë ¥
    print("\n[2/3] í´ë˜ìŠ¤ ë¶„í¬ ë¶„ì„")
    train_dist = Counter(train_classes)
    val_dist = Counter(val_classes)

    class_names = data["names"]
    print("\nğŸ“ˆ í•™ìŠµ ë°ì´í„° í´ë˜ìŠ¤ ë¶„í¬:")
    for class_id, count in sorted(train_dist.items()):
        class_name = class_names[class_id]
        percentage = count / len(train_classes) * 100
        print(f"  {class_name:20s}: {count:6d} ({percentage:5.2f}%)")

    print("\nğŸ“ˆ ê²€ì¦ ë°ì´í„° í´ë˜ìŠ¤ ë¶„í¬:")
    for class_id, count in sorted(val_dist.items()):
        class_name = class_names[class_id]
        percentage = count / len(val_classes) * 100
        print(f"  {class_name:20s}: {count:6d} ({percentage:5.2f}%)")

    # í´ë˜ìŠ¤ ë¶ˆê· í˜• ì²´í¬
    max_count = max(train_dist.values())
    min_count = min(train_dist.values())
    imbalance_ratio = max_count / min_count

    print(f"\nâš–ï¸  í´ë˜ìŠ¤ ë¶ˆê· í˜• ë¹„ìœ¨: {imbalance_ratio:.2f}:1")
    if imbalance_ratio > 3.0:
        print("   âš ï¸  ê²½ê³ : í´ë˜ìŠ¤ ë¶ˆê· í˜•ì´ ì‹¬í•©ë‹ˆë‹¤. ê°€ì¤‘ì¹˜ ì¡°ì • ê¶Œì¥!")

    return {
        "train_distribution": train_dist,
        "val_distribution": val_dist,
        "class_names": class_names,
        "imbalance_ratio": imbalance_ratio,
    }


def preprocess_images(data_yaml: str, apply_clahe: bool = False):
    """
    ì´ë¯¸ì§€ ì „ì²˜ë¦¬ (ì„ íƒì‚¬í•­)

    Args:
        data_yaml: data.yaml ê²½ë¡œ
        apply_clahe: CLAHE (ëŒ€ë¹„ í–¥ìƒ) ì ìš© ì—¬ë¶€

    Note:
        ê¸°ë³¸ì ìœ¼ë¡œ YOLO ìì²´ ì¦ê°•ì´ ê°•ë ¥í•˜ë¯€ë¡œ,
        ë°ì´í„°ê°€ ì¶©ë¶„í•˜ë©´ ì „ì²˜ë¦¬ ì—†ì´ë„ í•™ìŠµ ê°€ëŠ¥.
        í•„ìš”ì‹œ apply_clahe=Trueë¡œ ì‹¤í–‰.
    """
    if not apply_clahe:
        print("\nâœ… ì „ì²˜ë¦¬ ìŠ¤í‚µ (YOLO ìì²´ ì¦ê°• ì‚¬ìš©)")
        return

    print("\n" + "=" * 60)
    print("ğŸ”§ ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ì ìš© ì¤‘ (CLAHE)...")
    print("=" * 60)

    with open(data_yaml, "r", encoding="utf-8") as f:
        data = yaml.safe_load(f)

    data_path = Path(data["path"])
    train_images = data_path / data["train"]

    # CLAHE ê°ì²´ ìƒì„±
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))

    processed_dir = data_path / "images" / "train_preprocessed"
    processed_dir.mkdir(exist_ok=True)

    print(f"\nì²˜ë¦¬ëœ ì´ë¯¸ì§€ ì €ì¥ ìœ„ì¹˜: {processed_dir}")
    print("â€» ì›ë³¸ ì´ë¯¸ì§€ëŠ” ìœ ì§€ë©ë‹ˆë‹¤.\n")

    for img_path in tqdm(
        list(train_images.glob("*.jpg")) + list(train_images.glob("*.png"))
    ):
        img = cv2.imread(str(img_path))

        # LAB ìƒ‰ê³µê°„ìœ¼ë¡œ ë³€í™˜ â†’ L ì±„ë„ì—ë§Œ CLAHE ì ìš©
        lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)
        l, a, b = cv2.split(lab)
        l_clahe = clahe.apply(l)
        enhanced = cv2.merge([l_clahe, a, b])
        enhanced_bgr = cv2.cvtColor(enhanced, cv2.COLOR_LAB2BGR)

        # ì €ì¥
        output_path = processed_dir / img_path.name
        cv2.imwrite(str(output_path), enhanced_bgr)

    print(f"\nâœ… ì „ì²˜ë¦¬ ì™„ë£Œ! data.yamlì˜ train ê²½ë¡œë¥¼ ë³€ê²½í•˜ì—¬ ì‚¬ìš©í•˜ì„¸ìš”:")
    print(f"   train: images/train_preprocessed")


# ============================================================================
# 2. ê³ ë„í™” í•™ìŠµ
# ============================================================================


def train_model(
    data_yaml: str,
    model_size: str = "s",  # ê¸°ë³¸ê°’ì„ 's'ë¡œ ë³€ê²½ (nano â†’ small)
    epochs: int = 150,  # ì—í¬í¬ ì¦ê°€
    imgsz: int = 640,
    batch: int = 16,
    device: str = "0",
    project: str = "runs/detect",
    name: str = "egg_classifier_advanced",
    # ê³ ê¸‰ ì˜µì…˜
    optimizer: str = "auto",  # auto, SGD, Adam, AdamW
    use_advanced_aug: bool = True,
    early_stopping: int = 30,
    warmup_epochs: int = 5,
    cos_lr: bool = True,  # Cosine learning rate scheduler
    pretrained: bool = True,
    # í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ (ë¶ˆê· í˜• ëŒ€ì‘)
    auto_weight: bool = False,
):
    """
    YOLOv8 ê³ ë„í™” í•™ìŠµ

    ì„±ëŠ¥ ê°œì„  í¬ì¸íŠ¸:
    1. ëª¨ë¸ í¬ê¸° ì—…ê·¸ë ˆì´ë“œ (n â†’ s/m)
    2. ê³ ê¸‰ ë°ì´í„° ì¦ê°• (CopyPaste, MixUp)
    3. Learning rate ìŠ¤ì¼€ì¤„ë§ (Cosine Annealing)
    4. Warm-up + Early stopping ì¡°ì •
    """

    # ì‚¬ì „ í•™ìŠµ ëª¨ë¸ ë¡œë“œ
    if pretrained:
        model_name = f"yolov8{model_size}.pt"
        print(f"\nâœ… ì‚¬ì „í•™ìŠµ ëª¨ë¸ ë¡œë“œ: {model_name}")
    else:
        model_name = f"yolov8{model_size}.yaml"
        print(f"\nâš ï¸  ì²˜ìŒë¶€í„° í•™ìŠµ (ì‚¬ì „í•™ìŠµ ì—†ìŒ): {model_name}")

    model = YOLO(model_name)

    # í•™ìŠµ ì„¤ì • ì¶œë ¥
    print("\n" + "=" * 60)
    print("ğŸš€ í•™ìŠµ ì‹œì‘")
    print("=" * 60)
    print(f"  ğŸ“ ë°ì´í„°: {data_yaml}")
    print(f"  ğŸ¤– ëª¨ë¸: YOLOv8{model_size.upper()}")
    print(f"  ğŸ“Š ì—í¬í¬: {epochs}")
    print(f"  ğŸ–¼ï¸  ì´ë¯¸ì§€ í¬ê¸°: {imgsz}")
    print(f"  ğŸ“¦ ë°°ì¹˜ í¬ê¸°: {batch}")
    print(f"  ğŸ¯ ì˜µí‹°ë§ˆì´ì €: {optimizer}")
    print(f"  ğŸ”„ ê³ ê¸‰ ì¦ê°•: {'ON' if use_advanced_aug else 'OFF'}")
    print(f"  ğŸ“ˆ Cosine LR: {'ON' if cos_lr else 'OFF'}")
    print(f"  ğŸ”¥ Warm-up: {warmup_epochs} epochs")
    print(f"  â¸ï¸  Early stopping: {early_stopping} patience")
    print("=" * 60 + "\n")

    # ========================================
    # í•™ìŠµ íŒŒë¼ë¯¸í„° ì„¤ì •
    # ========================================
    train_args = {
        "data": data_yaml,
        "epochs": epochs,
        "imgsz": imgsz,
        "batch": batch,
        "device": device,
        "project": project,
        "name": name,
        # ê¸°ë³¸ ì„¤ì •
        "patience": early_stopping,
        "save": True,
        "save_period": 10,
        "plots": True,
        "verbose": True,
        "workers": 4,
        # Optimizer & Learning Rate
        "optimizer": optimizer,
        "lr0": 0.01,  # ì´ˆê¸° learning rate
        "lrf": 0.01,  # ìµœì¢… learning rate (lr0ì˜ ë¹„ìœ¨)
        "warmup_epochs": warmup_epochs,
        "warmup_momentum": 0.8,
        "cos_lr": cos_lr,  # Cosine annealing
        # ì •ê·œí™”
        "weight_decay": 0.0005,
        "dropout": 0.0,
    }

    # ========================================
    # ë°ì´í„° ì¦ê°• ì„¤ì •
    # ========================================
    if use_advanced_aug:
        print("ğŸ¨ ê³ ê¸‰ ë°ì´í„° ì¦ê°• í™œì„±í™”\n")
        train_args.update(
            {
                # ê¸°ë³¸ ì¦ê°• (ë” ê°•í•˜ê²Œ)
                "hsv_h": 0.02,  # ìƒ‰ì¡° (0.015 â†’ 0.02)
                "hsv_s": 0.7,  # ì±„ë„
                "hsv_v": 0.4,  # ëª…ë„
                "degrees": 15.0,  # íšŒì „ (10 â†’ 15ë„)
                "translate": 0.1,  # ì´ë™
                "scale": 0.5,  # ìŠ¤ì¼€ì¼
                "shear": 0.0,  # ì „ë‹¨ ë³€í˜•
                "perspective": 0.0,  # ì›ê·¼ ë³€í˜•
                "flipud": 0.5,  # ìƒí•˜ ë°˜ì „
                "fliplr": 0.5,  # ì¢Œìš° ë°˜ì „
                # YOLO íŠ¹í™” ì¦ê°•
                "mosaic": 1.0,  # ëª¨ìì´í¬ (4ê°œ ì´ë¯¸ì§€ í•©ì„±)
                "mixup": 0.1,  # MixUp (ì´ë¯¸ì§€ í˜¼í•©) â† ìƒˆë¡œ ì¶”ê°€!
                "copy_paste": 0.1,  # CopyPaste (ê°ì²´ ë³µë¶™) â† ìƒˆë¡œ ì¶”ê°€!
                # í’ˆì§ˆ ì¦ê°•
                "blur": 0.0,  # ë¸”ëŸ¬ (0~1)
                "auto_augment": "randaugment",  # AutoAugment
                "erasing": 0.4,  # Random Erasing
            }
        )
    else:
        # ê¸°ë³¸ ì¦ê°•ë§Œ ì‚¬ìš©
        train_args.update(
            {
                "augment": True,
                "hsv_h": 0.015,
                "hsv_s": 0.7,
                "hsv_v": 0.4,
                "degrees": 10.0,
                "translate": 0.1,
                "scale": 0.5,
                "flipud": 0.5,
                "fliplr": 0.5,
                "mosaic": 1.0,
            }
        )

    # ========================================
    # í•™ìŠµ ì‹œì‘
    # ========================================
    results = model.train(**train_args)

    # ========================================
    # ê²°ê³¼ ì¶œë ¥
    # ========================================
    print("\n" + "=" * 60)
    print("ğŸ‰ í•™ìŠµ ì™„ë£Œ!")
    print("=" * 60)

    best_model = Path(project) / name / "weights" / "best.pt"
    last_model = Path(project) / name / "weights" / "last.pt"

    print(f"\nğŸ“¦ ëª¨ë¸ ì €ì¥ ìœ„ì¹˜:")
    print(f"  Best: {best_model}")
    print(f"  Last: {last_model}")

    # ìµœì¢… ë©”íŠ¸ë¦­ ì¶œë ¥
    if hasattr(results, "results_dict"):
        metrics = results.results_dict
        print(f"\nğŸ“Š ìµœì¢… ê²€ì¦ ë©”íŠ¸ë¦­:")
        print(f"  mAP50:       {metrics.get('metrics/mAP50(B)', 0):.4f}")
        print(f"  mAP50-95:    {metrics.get('metrics/mAP50-95(B)', 0):.4f}")
        print(f"  Precision:   {metrics.get('metrics/precision(B)', 0):.4f}")
        print(f"  Recall:      {metrics.get('metrics/recall(B)', 0):.4f}")

    print("\n" + "=" * 60)
    print("ğŸ’¡ ë‹¤ìŒ ë‹¨ê³„:")
    print("  1. í•™ìŠµ ê²°ê³¼ í™•ì¸: runs/detect/{}/".format(name))
    print("  2. ONNX ë‚´ë³´ë‚´ê¸°: python export_onnx.py --model {}".format(best_model))
    print("  3. ê²€ì¦ ì‹¤í–‰: python train.py --validate-only {}".format(best_model))
    print("=" * 60 + "\n")

    return best_model


def validate_model(model_path: str, data_yaml: str):
    """í•™ìŠµëœ ëª¨ë¸ ê²€ì¦"""
    print("\n" + "=" * 60)
    print(f"ğŸ” ëª¨ë¸ ê²€ì¦: {model_path}")
    print("=" * 60 + "\n")

    model = YOLO(model_path)
    results = model.val(data=data_yaml, verbose=True, plots=True)

    return results


# ============================================================================
# 3. í•˜ì´í¼íŒŒë¼ë¯¸í„° ìë™ íŠœë‹
# ============================================================================


def tune_hyperparameters(
    data_yaml: str, model_size: str = "s", iterations: int = 30, device: str = "0"
):
    """
    Ray Tuneì„ ì‚¬ìš©í•œ í•˜ì´í¼íŒŒë¼ë¯¸í„° ìë™ ìµœì í™”

    ì£¼ì˜: ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦½ë‹ˆë‹¤ (GPU í•„ìˆ˜)
    iterations=10ì´ë©´ ì•½ 1~2ì‹œê°„ ì†Œìš”
    """
    print("\n" + "=" * 60)
    print("ğŸ”¬ í•˜ì´í¼íŒŒë¼ë¯¸í„° ìë™ íŠœë‹ ì‹œì‘")
    print("=" * 60)
    print(f"  ëª¨ë¸: YOLOv8{model_size}")
    print(f"  ë°˜ë³µ íšŸìˆ˜: {iterations}")
    print(f"  âš ï¸  ì˜ˆìƒ ì†Œìš” ì‹œê°„: {iterations * 3}~{iterations * 5}ë¶„")
    print("=" * 60 + "\n")

    model = YOLO(f"yolov8{model_size}.pt")

    # í•˜ì´í¼íŒŒë¼ë¯¸í„° íƒìƒ‰ ê³µê°„
    # YOLOëŠ” ìë™ìœ¼ë¡œ ìµœì  ë²”ìœ„ íƒìƒ‰
    result = model.tune(
        data=data_yaml,
        epochs=50,  # íŠœë‹ìš© ì—í¬í¬ (ì§§ê²Œ)
        iterations=iterations,
        device=device,
        plots=True,
        save=True,
        val=True,
    )

    print("\nâœ… íŠœë‹ ì™„ë£Œ! ìµœì  íŒŒë¼ë¯¸í„°ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    print("   ë‹¤ìŒ í•™ìŠµë¶€í„°ëŠ” ìë™ìœ¼ë¡œ ì ìš©ë©ë‹ˆë‹¤.")

    return result


# ============================================================================
# CLI ì§„ì…ì 
# ============================================================================

if __name__ == "__main__":
    parser = argparse.ArgumentParser(
        description="YOLOv8 ê³„ë€ ë¶„ë¥˜ ëª¨ë¸ ê³ ë„í™” í•™ìŠµ",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ì‚¬ìš© ì˜ˆì‹œ:
  # ê¸°ë³¸ í•™ìŠµ (YOLOv8s, ê³ ê¸‰ ì¦ê°•)
  python train.py --data ../data/data.yaml --model s

  # ê³ ì„±ëŠ¥ ëª¨ë¸ (YOLOv8m)
  python train.py --data ../data/data.yaml --model m --epochs 200

  # ë°ì´í„° ë¶„ì„ë§Œ ìˆ˜í–‰
  python train.py --analyze-only

  # ëª¨ë¸ ê²€ì¦
  python train.py --validate-only runs/detect/egg_classifier_advanced/weights/best.pt

  # í•˜ì´í¼íŒŒë¼ë¯¸í„° ìë™ íŠœë‹
  python train.py --tune --model s --iterations 20
        """,
    )

    # ê¸°ë³¸ ì¸ì
    parser.add_argument(
        "--data", type=str, default="../data/data.yaml", help="data.yaml ê²½ë¡œ"
    )
    parser.add_argument(
        "--model",
        type=str,
        default="s",
        choices=["n", "s", "m", "l", "x"],
        help="ëª¨ë¸ í¬ê¸° (s=ì¶”ì²œ, m=ê³ ì„±ëŠ¥)",
    )
    parser.add_argument("--epochs", type=int, default=150, help="ì—í¬í¬ ìˆ˜ (ê¸°ë³¸ 150)")
    parser.add_argument("--imgsz", type=int, default=640, help="ì…ë ¥ ì´ë¯¸ì§€ í¬ê¸°")
    parser.add_argument("--batch", type=int, default=16, help="ë°°ì¹˜ í¬ê¸°")
    parser.add_argument("--device", type=str, default="0", help="GPU ì¥ì¹˜ (0) ë˜ëŠ” cpu")
    parser.add_argument(
        "--name", type=str, default="egg_classifier_advanced", help="ì‹¤í—˜ ì´ë¦„"
    )

    # ê³ ê¸‰ ì˜µì…˜
    parser.add_argument(
        "--optimizer",
        type=str,
        default="auto",
        choices=["auto", "SGD", "Adam", "AdamW"],
        help="ì˜µí‹°ë§ˆì´ì € ì„ íƒ",
    )
    parser.add_argument(
        "--no-advanced-aug", action="store_true", help="ê³ ê¸‰ ì¦ê°• ë¹„í™œì„±í™”"
    )
    parser.add_argument(
        "--early-stop", type=int, default=30, help="Early stopping patience"
    )
    parser.add_argument("--warmup", type=int, default=5, help="Warm-up epochs")
    parser.add_argument(
        "--no-pretrained", action="store_true", help="ì‚¬ì „í•™ìŠµ ëª¨ë¸ ì‚¬ìš© ì•ˆí•¨"
    )

    # ì „ì²˜ë¦¬ ì˜µì…˜
    parser.add_argument(
        "--preprocess-clahe", action="store_true", help="CLAHE ì „ì²˜ë¦¬ ì ìš© (ì„ íƒ)"
    )

    # íŠ¹ìˆ˜ ëª¨ë“œ
    parser.add_argument(
        "--analyze-only", action="store_true", help="ë°ì´í„° ë¶„ì„ë§Œ ìˆ˜í–‰"
    )
    parser.add_argument(
        "--validate-only", type=str, default=None, help="íŠ¹ì • ëª¨ë¸ë§Œ ê²€ì¦"
    )
    parser.add_argument("--tune", action="store_true", help="í•˜ì´í¼íŒŒë¼ë¯¸í„° ìë™ íŠœë‹")
    parser.add_argument(
        "--tune-iterations", type=int, default=30, help="íŠœë‹ ë°˜ë³µ íšŸìˆ˜"
    )

    args = parser.parse_args()

    # ========================================
    # ì‹¤í–‰ ëª¨ë“œ ë¶„ê¸°
    # ========================================

    # 1. ë°ì´í„° ë¶„ì„ë§Œ
    if args.analyze_only:
        analyze_dataset(args.data)
        exit(0)

    # 2. ëª¨ë¸ ê²€ì¦ë§Œ
    if args.validate_only:
        validate_model(args.validate_only, args.data)
        exit(0)

    # 3. í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹í•˜ê¸°
    if args.tune:
        tune_hyperparameters(
            data_yaml=args.data,
            model_size=args.model,
            iterations=args.tune_iterations,
            device=args.device,
        )
        exit(0)

    # 4. ì „ì²´ íŒŒì´í”„ë¼ì¸ (ë¶„ì„ â†’ ì „ì²˜ë¦¬ â†’ í•™ìŠµ)
    print(
        """
    â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
    â•‘         YOLOv8 ê³„ë€ í’ˆì§ˆ ë¶„ë¥˜ ëª¨ë¸ ê³ ë„í™” í•™ìŠµ               â•‘
    â•‘                                                               â•‘
    â•‘  ì „ì²˜ë¦¬ + ë°ì´í„° ë¶„ì„ + í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™” í†µí•©           â•‘
    â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """
    )

    # Step 1: ë°ì´í„° ë¶„ì„
    stats = analyze_dataset(args.data)

    # Step 2: ì „ì²˜ë¦¬ (ì„ íƒì‚¬í•­)
    preprocess_images(args.data, apply_clahe=args.preprocess_clahe)

    # Step 3: í•™ìŠµ
    input("\në¶„ì„ ì™„ë£Œ! ì—”í„°ë¥¼ ëˆŒëŸ¬ í•™ìŠµì„ ì‹œì‘í•˜ì„¸ìš”... (Ctrl+Cë¡œ ì·¨ì†Œ)")

    train_model(
        data_yaml=args.data,
        model_size=args.model,
        epochs=args.epochs,
        imgsz=args.imgsz,
        batch=args.batch,
        device=args.device,
        name=args.name,
        optimizer=args.optimizer,
        use_advanced_aug=not args.no_advanced_aug,
        early_stopping=args.early_stop,
        warmup_epochs=args.warmup,
        pretrained=not args.no_pretrained,
    )
